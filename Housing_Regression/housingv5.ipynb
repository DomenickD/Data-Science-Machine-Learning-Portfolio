{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# models\n",
    "import xgboost as xgb  # pip install xgboost\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor,\n",
    "    BaggingRegressor,\n",
    "    StackingRegressor,\n",
    "    VotingRegressor,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, learning_curve, validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "columns = [\n",
    "    \"Overall Qual\",\n",
    "    \"Overall Cond\",\n",
    "    \"Gr Liv Area\",\n",
    "    \"Central Air\",\n",
    "    \"Total Bsmt SF\",\n",
    "    \"SalePrice\",\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"AmesHousing.txt\", sep=\"\\t\", usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "df[\"Central_Air_Binary\"] = df[\"Central Air\"].map({\"N\": 0, \"Y\": 1})\n",
    "df = df.dropna(axis=0)\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.drop([\"Central Air\", \"SalePrice\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init models\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "# xgb_model =xgb.XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
    "#                               colsample_bylevel=None, colsample_bynode=None,\n",
    "#                               colsample_bytree=1.0, device=None,\n",
    "#                               early_stopping_rounds=None,\n",
    "#                               enable_categorical=False, eval_metric=None,\n",
    "#                               feature_types=None, gamma=0.5, grow_policy=None,\n",
    "#                               importance_type=None,\n",
    "#                               interaction_constraints=None, learning_rate=0.01,\n",
    "#                               max_bin=None, max_cat_threshold=None,\n",
    "#                               max_cat_to_onehot=None, max_delta_step=None,\n",
    "#                               max_depth=5, max_leaves=None,\n",
    "#                               min_child_weight=None, monotone_constraints=None, multi_strategy=None,\n",
    "#                               n_estimators=300, n_jobs=None,\n",
    "#                               num_parallel_tree=None)\n",
    "rfr_model = RandomForestRegressor(\n",
    "    max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300\n",
    ")\n",
    "svr_model = SVR(C=10, epsilon=0.2)\n",
    "lass_model = Lasso(alpha=10)\n",
    "eln_model = ElasticNet(alpha=0.01, l1_ratio=0.95)\n",
    "lr_model = LinearRegression()\n",
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline_xgb = Pipeline([(\"scaler\", scaler), (\"xgb\", xgb_model)])\n",
    "\n",
    "pipeline_rfr = Pipeline([(\"scaler\", scaler), (\"rfr\", rfr_model)])\n",
    "\n",
    "\n",
    "pipeline_svr = Pipeline([(\"scaler\", scaler), (\"svr\", svr_model)])\n",
    "\n",
    "pipeline_lass = Pipeline([(\"scaler\", scaler), (\"lass\", lass_model)])\n",
    "\n",
    "pipeline_eln = Pipeline([(\"scaler\", scaler), (\"eln\", eln_model)])\n",
    "\n",
    "pipeline_lr = Pipeline([(\"scaler\", scaler), (\"lr\", lr_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_xgb: 0.8762718300369723\n",
      "r2_rfr: 0.8361987683778861\n",
      "r2_svr: -0.019077327120919696\n",
      "r2_lass: 0.6712619895673891\n",
      "r2_eln: 0.6730473184293602\n",
      "r2_lr: 0.6708452385884899\n"
     ]
    }
   ],
   "source": [
    "# fit models and display accuracy\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "pipeline_rfr.fit(X_train, y_train)\n",
    "pipeline_svr.fit(X_train, y_train)\n",
    "pipeline_lass.fit(X_train, y_train)\n",
    "pipeline_eln.fit(X_train, y_train)\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "ypred_xgb = pipeline_xgb.predict(X_test)\n",
    "ypred_rfr = pipeline_rfr.predict(X_test)\n",
    "ypred_svr = pipeline_svr.predict(X_test)\n",
    "ypred_lass = pipeline_lass.predict(X_test)\n",
    "ypred_eln = pipeline_eln.predict(X_test)\n",
    "ypred_lr = pipeline_lr.predict(X_test)\n",
    "\n",
    "r2_xgb = r2_score(y_test, ypred_xgb)\n",
    "r2_rfr = r2_score(y_test, ypred_rfr)\n",
    "r2_svr = r2_score(y_test, ypred_svr)\n",
    "r2_lass = r2_score(y_test, ypred_lass)\n",
    "r2_eln = r2_score(y_test, ypred_eln)\n",
    "r2_lr = r2_score(y_test, ypred_lr)\n",
    "\n",
    "print(f\"r2_xgb: {r2_xgb}\")\n",
    "print(f\"r2_rfr: {r2_rfr}\")\n",
    "print(f\"r2_svr: {r2_svr}\")\n",
    "print(f\"r2_lass: {r2_lass}\")\n",
    "print(f\"r2_eln: {r2_eln}\")\n",
    "print(f\"r2_lr: {r2_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2_xgb: 0.8762718300369723\n",
    "\n",
    "r2_rfr: 0.8637605575807634\n",
    "\n",
    "r2_svr: -0.046523512399574196\n",
    "\n",
    "r2_lass: 0.6708874959350789\n",
    "\n",
    "r2_eln: 0.11013549601961803\n",
    "\n",
    "r2_lr: 0.6708452385884899\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grids for models\n",
    "# XGBoost Regressor\n",
    "xgb_params = {\n",
    "    \"xgb__n_estimators\": [100, 200, 300],  # Number of boosting rounds\n",
    "    \"xgb__max_depth\": [3, 5, 7],  # Maximum depth of a tree\n",
    "    \"xgb__learning_rate\": [\n",
    "        0.1,\n",
    "        0.01,\n",
    "        0.001,\n",
    "    ],  # Step size shrinkage used in update to prevents overfitting\n",
    "    \"xgb__subsample\": [0.8, 0.9, 1.0],  # Subsample ratio of the training instance\n",
    "    \"xgb__colsample_bytree\": [\n",
    "        0.8,\n",
    "        0.9,\n",
    "        1.0,\n",
    "    ],  # Subsample ratio of columns when constructing each tree\n",
    "    \"xgb__gamma\": [\n",
    "        0,\n",
    "        0.25,\n",
    "        0.5,\n",
    "    ],  # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "}\n",
    "\n",
    "# Random Forest Regressor\n",
    "rfr_params = {\n",
    "    \"rfr__n_estimators\": [100, 200, 300],  # Number of trees in the forest\n",
    "    \"rfr__max_depth\": [None, 10, 20],  # Maximum depth of the tree\n",
    "    \"rfr__min_samples_split\": [\n",
    "        2,\n",
    "        5,\n",
    "        10,\n",
    "    ],  # Minimum number of samples required to split an internal node\n",
    "    \"rfr__min_samples_leaf\": [\n",
    "        1,\n",
    "        2,\n",
    "        4,\n",
    "    ],  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Support Vector Regressor\n",
    "svr_params = {\n",
    "    \"svr__kernel\": [\"linear\", \"rbf\"],  # Kernel type\n",
    "    \"svr__C\": [\n",
    "        0.1,\n",
    "        1,\n",
    "        10,\n",
    "    ],  # Regularization parameter. The strength of the regularization is inversely proportional to C\n",
    "    \"svr__gamma\": [\n",
    "        \"scale\",\n",
    "        \"auto\",\n",
    "    ],  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "}\n",
    "\n",
    "# Lasso Regressor\n",
    "lasso_params = {\n",
    "    \"lass__alpha\": [0.01, 0.1, 1, 10],  # Constant that multiplies the L1 term.\n",
    "}\n",
    "\n",
    "# Elastic Net Regressor\n",
    "elasticnet_params = {\n",
    "    \"eln__alpha\": [0.01, 0.1, 1, 10],  # Constant that multiplies the penalty terms\n",
    "    \"eln__l1_ratio\": [\n",
    "        0.1,\n",
    "        0.5,\n",
    "        0.7,\n",
    "        0.9,\n",
    "        0.95,\n",
    "        0.99,\n",
    "        1,\n",
    "    ],  # The ElasticNet mixing parameter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearchCV\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    pipeline_xgb, param_distributions=xgb_params, cv=5, scoring=\"r2\", n_jobs=3\n",
    ")\n",
    "random_search_rfr = RandomizedSearchCV(\n",
    "    pipeline_rfr, param_distributions=rfr_params, cv=5, scoring=\"r2\", n_jobs=3\n",
    ")\n",
    "random_search_svr = RandomizedSearchCV(\n",
    "    pipeline_svr, param_distributions=svr_params, cv=5, scoring=\"r2\", n_jobs=3\n",
    ")\n",
    "random_search_lass = RandomizedSearchCV(\n",
    "    pipeline_lass, param_distributions=lasso_params, cv=5, scoring=\"r2\", n_jobs=3\n",
    ")\n",
    "random_search_eln = RandomizedSearchCV(\n",
    "    pipeline_eln, param_distributions=elasticnet_params, cv=5, scoring=\"r2\", n_jobs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_xgb: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('xgb',\n",
      "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "                              colsample_bylevel=None, colsample_bynode=None,\n",
      "                              colsample_bytree=1.0, device=None,\n",
      "                              early_stopping_rounds=None,\n",
      "                              enable_categorical=False, eval_metric=None,\n",
      "                              feature_types=None, gamma=0, grow_policy=None,\n",
      "                              importance_type=None,\n",
      "                              interaction_constraints=None, learning_rate=0.1,\n",
      "                              max_bin=None, max_cat_threshold=None,\n",
      "                              max_cat_to_onehot=None, max_delta_step=None,\n",
      "                              max_depth=3, max_leaves=None,\n",
      "                              min_child_weight=None, missing=nan,\n",
      "                              monotone_constraints=None, multi_strategy=None,\n",
      "                              n_estimators=100, n_jobs=None,\n",
      "                              num_parallel_tree=None, random_state=None, ...))])\n",
      "best_rfr: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('rfr',\n",
      "                 RandomForestRegressor(min_samples_leaf=2,\n",
      "                                       min_samples_split=10))])\n",
      "best_svr: Pipeline(steps=[('scaler', MinMaxScaler()), ('svr', SVR(C=10, epsilon=0.2))])\n",
      "best_lass: Pipeline(steps=[('scaler', MinMaxScaler()), ('lass', Lasso(alpha=10))])\n",
      "best_eln: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('eln', ElasticNet(alpha=0.01, l1_ratio=0.95))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Domenick Dobbs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "random_search_xgb.fit(X_train, y_train)\n",
    "random_search_rfr.fit(X_train, y_train)\n",
    "random_search_svr.fit(X_train, y_train)\n",
    "random_search_lass.fit(X_train, y_train)\n",
    "random_search_eln.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "best_rfr = random_search_rfr.best_estimator_\n",
    "best_svr = random_search_svr.best_estimator_\n",
    "best_lass = random_search_lass.best_estimator_\n",
    "best_eln = random_search_eln.best_estimator_\n",
    "\n",
    "print(f\"best_xgb: {best_xgb}\")\n",
    "print(f\"best_rfr: {best_rfr}\")\n",
    "print(f\"best_svr: {best_svr}\")\n",
    "print(f\"best_lass: {best_lass}\")\n",
    "print(f\"best_eln: {best_eln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_xgb: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                ('xgb',\n",
    "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
    "                              colsample_bylevel=None, colsample_bynode=None,\n",
    "                              colsample_bytree=1.0, device=None,\n",
    "                              early_stopping_rounds=None,\n",
    "                              enable_categorical=False, eval_metric=None,\n",
    "                              feature_types=None, gamma=0.5, grow_policy=None,\n",
    "                              importance_type=None,\n",
    "                              interaction_constraints=None, learning_rate=0.01,\n",
    "                              max_bin=None, max_cat_threshold=None,\n",
    "                              max_cat_to_onehot=None, max_delta_step=None,\n",
    "                              max_depth=5, max_leaves=None,\n",
    "                              min_child_weight=None, missing=nan,\n",
    "                              monotone_constraints=None, multi_strategy=None,\n",
    "                              n_estimators=300, n_jobs=None,\n",
    "                              num_parallel_tree=None, random_state=None, ...))])\n",
    "\n",
    "\n",
    "best_rfr: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                ('rfr',\n",
    "                 RandomForestRegressor(max_depth=10, min_samples_leaf=4,\n",
    "                                       min_samples_split=10,\n",
    "                                       n_estimators=300))])\n",
    "\n",
    "\n",
    "best_svr: Pipeline(steps=[('scaler', MinMaxScaler()), ('svr', SVR(C=10, epsilon=0.2))])\n",
    "\n",
    "\n",
    "best_lass: Pipeline(steps=[('scaler', MinMaxScaler()), ('lass', Lasso(alpha=10))])\n",
    "\n",
    "\n",
    "best_eln: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                ('eln', ElasticNet(alpha=0.01, l1_ratio=0.95))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_model: 0.8884924653504968\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "bagging_model = BaggingRegressor(estimator=xgb_model, n_estimators=10, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"xgb_model: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booster_model: 0.8933634174946422\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "booster = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "y_pred = booster.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"booster_model: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "level1_models = [(\"svr\", svr_model), (\"lass\", lass_model), (\"rfr\", rfr_model)]\n",
    "# Define the final estimator (meta-learner) for the second level\n",
    "final_estimator = xgb_model  # for example. Can use anything else - maybe try some hyperparameter tuning first?\n",
    "\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=level1_models, final_estimator=final_estimator, cv=5\n",
    ")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Model R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting Model Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "# voting\n",
    "voting_model = VotingRegressor(estimators=level1_models)\n",
    "voting_model.fit(X_train, y_train)\n",
    "y_pred = voting_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Majority Voting Model R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
