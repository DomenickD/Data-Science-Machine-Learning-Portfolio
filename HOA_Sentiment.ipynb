{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "# First Import the libraries to use. I will keep all of the imports in the top box.\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import string\n",
    "import inflect\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Import Counter class of collection containers library (to analyze the data):\n",
    "from collections import Counter\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import gensim\n",
    "import spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions that will be used here\n",
    "# https://www.geeksforgeeks.org/text-preprocessing-in-python-set-1/\n",
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    "    result = re.sub(r'\\d+', '', text)\n",
    "    return result\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r',|\\.|\\:|;|-|\\'|/|&|!|\\?|\\(|\\)|\\+|@|<|>|#|~|=|\\$|\\*|[|]|{|}','',text)\n",
    "\n",
    "# remove whitespace from text\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "\n",
    "# remove stopwords function\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return filtered_text\n",
    "\n",
    "# stem words in the list of tokenized words\n",
    "# Instantiate an object of the PorterStemmer() class:\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stems = [stemmer.stem(word) for word in word_tokens]\n",
    "    return stems\n",
    "\n",
    "# lemmatize string\n",
    "# Instantiate an object of the WordNetLemmatizer() class:\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_word(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    # provide context i.e. part-of-speech\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens]\n",
    "    return lemmas\n",
    "\n",
    "# toeknize words\n",
    "def toeknize_words(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# convert number into words\n",
    "# Instantiate an object of the inflect.engine() class:\n",
    "p = inflect.engine()\n",
    "def convert_number(text):\n",
    "    # split string into list of words\n",
    "    temp_str = text.split()\n",
    "    # initialise empty list\n",
    "    new_string = []\n",
    " \n",
    "    for word in temp_str:\n",
    "        # if word is a digit, convert the digit\n",
    "        # to numbers and append into the new_string list\n",
    "        if word.isdigit():\n",
    "            temp = p.number_to_words(word)\n",
    "            new_string.append(temp)\n",
    " \n",
    "        # append the word as it is\n",
    "        else:\n",
    "            new_string.append(word)\n",
    " \n",
    "    # join the words of new_string to form a string\n",
    "    temp_str = ' '.join(new_string)\n",
    "    return temp_str\n",
    "\n",
    "def get_part_of_speech(word):\n",
    "    probable_part_of_speech = wordnet.synsets(word)\n",
    "    pos_counts = Counter()\n",
    "    pos_counts[\"n\"] = len([item for item in probable_part_of_speech if item.pos()==\"n\"])\n",
    "    pos_counts[\"v\"] = len([item for item in probable_part_of_speech if item.pos()==\"v\"])\n",
    "    pos_counts[\"a\"] = len([item for item in probable_part_of_speech if item.pos()==\"a\"])\n",
    "    pos_counts[\"r\"] = len([item for item in probable_part_of_speech if item.pos()==\"r\"])\n",
    "    most_likely_part_of_speech = pos_counts.most_common(1)[0][0]\n",
    "    return most_likely_part_of_speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and paste the text here\n",
    "content = \"We are happy that you have chosen to be a part of our community. To maintain property values\\\n",
    "and to ensure that Breakwater Cove continues to be a desirable place to live, we all must do\\\n",
    "our part. To that end all residents must have their lawn mowed, edged and weeded to ensure a\\\n",
    "neat appearance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are happy that you have chosen to be a part of our community.',\n",
       " 'To maintain property valuesand to ensure that Breakwater Cove continues to be a desirable place to live, we all must doour part.',\n",
       " 'To that end all residents must have their lawn mowed, edged and weeded to ensure aneat appearance.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert each sentence to a list of words. split on whitespace\n",
    "sentences = sent_tokenize(content)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are happy that you have chosen to be a part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To maintain property valuesand to ensure that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To that end all residents must have their lawn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0  We are happy that you have chosen to be a part...\n",
       "1  To maintain property valuesand to ensure that ...\n",
       "2  To that end all residents must have their lawn..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# form dataframe from sentences. \n",
    "df = pd.DataFrame(sentences, columns=['sentences'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are happy that you have chosen to be a part of our community',\n",
       " 'To maintain property valuesand to ensure that Breakwater Cove continues to be a desirable place to live we all must doour part',\n",
       " 'To that end all residents must have their lawn mowed edged and weeded to ensure aneat appearance']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctiation\n",
    "sentences_n0_punct = [remove_punctuation(sentence) for sentence in sentences]\n",
    "sentences_n0_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we are happy that you have chosen to be a part of our community',\n",
       " 'to maintain property valuesand to ensure that breakwater cove continues to be a desirable place to live we all must doour part',\n",
       " 'to that end all residents must have their lawn mowed edged and weeded to ensure aneat appearance']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Lower case\n",
    "content_lower_no_punct = [text_lowercase(sentence) for sentence in sentences_n0_punct]\n",
    "content_lower_no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we are happy that you have chosen to be a part of our community',\n",
       " 'to maintain property valuesand to ensure that breakwater cove continues to be a desirable place to live we all must doour part',\n",
       " 'to that end all residents must have their lawn mowed edged and weeded to ensure aneat appearance']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the white space\n",
    "content_lower_no_punct_white = [remove_whitespace(sentence) for sentence in content_lower_no_punct]\n",
    "content_lower_no_punct_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we are happy that you have chosen to be a part of our community',\n",
       " 'to maintain property valuesand to ensure that breakwater cove continues to be a desirable place to live we all must doour part',\n",
       " 'to that end all residents must have their lawn mowed edged and weeded to ensure aneat appearance']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numbers to words\n",
    "content_text = [convert_number(sentence) for sentence in content_lower_no_punct]\n",
    "content_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take SIA score and return \"Positive\" or \"Negative\"\n",
    "def sentiment_calc(column):\n",
    "    \"\"\"\n",
    "        Return a float for sentiment strength based on the input text.\n",
    "        Positive values are positive valence, negative value are negative\n",
    "        valence.\n",
    "    \"\"\"\n",
    "    temp_dict = sia.polarity_scores(column)\n",
    "    for row in column:\n",
    "        for item in row:\n",
    "            if (temp_dict[\"compound\"] > 0):\n",
    "                item = \"Positive\"\n",
    "            elif (temp_dict[\"compound\"] <= 0):\n",
    "                item = \"Negative\"\n",
    "        \n",
    "        # return item\n",
    "        return temp_dict[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5719, 0.5994, 0.3818]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the above function on every line in the dataframe\n",
    "content_text_sentiment = [sentiment_calc(sentence) for sentence in content_text]\n",
    "content_text_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive', 'Positive', 'Positive']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form an array to display results as \"Positive\" or \"Negative\"\n",
    "content_text_sentiment_classify = []\n",
    "\n",
    "for item in content_text_sentiment:\n",
    "    if (item > 0):\n",
    "        item_to_append = \"Positive\"\n",
    "    elif (item <= 0):\n",
    "        item_to_append = \"Negative\"\n",
    "    content_text_sentiment_classify.append(item_to_append)\n",
    "\n",
    "content_text_sentiment_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we are happy that you have chosen to be a part of our community',\n",
       " 'to maintain property valuesand to ensure that breakwater cove continues to be a desirable place to live we all must doour part',\n",
       " 'to that end all residents must have their lawn mowed edged and weeded to ensure aneat appearance']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>content_text_sentiment_classify</th>\n",
       "      <th>content_text_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are happy that you have chosen to be a part...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To maintain property valuesand to ensure that ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To that end all residents must have their lawn...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0  We are happy that you have chosen to be a part...   \n",
       "1  To maintain property valuesand to ensure that ...   \n",
       "2  To that end all residents must have their lawn...   \n",
       "\n",
       "  content_text_sentiment_classify  content_text_sentiment  \n",
       "0                        Positive                  0.5719  \n",
       "1                        Positive                  0.5994  \n",
       "2                        Positive                  0.3818  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare original with score forming new data frame for export\n",
    "# df['content_text'] = content_text\n",
    "df['content_text_sentiment_classify'] = content_text_sentiment_classify\n",
    "df['content_text_sentiment'] = content_text_sentiment\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "# df.to_csv('pressure_wash_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
